

```{r, message= FALSE}
library(readxl)
library(here)
library(tidyverse)
library(stringr)
library(naniar)
library(sf)
```

# Data Analysis

First let's get our processed data:
```{r}
df_simplified <- read_rds(here::here("data/processed/active_orgs.rds"))
```

Information about the data: 
https://nccs.urban.org/nccs/catalogs/catalog-bmf.html (to get MD file)
Here’s an [article](https://nccs.urban.org/nccs/datasets/bmf/) describing some of the datasets from the IRS 990s. We’re using the Business Master File (BMF).  There’s a section titled “Minimum Filing Threshold” that explains a data limitation (and why we’re seeing so many 0’s). See [here](https://www.irs.gov/charities-non-profits/exempt-organizations-annual-reporting-requirements-overview-annual-return-filing-exceptions) for more info.

It seems that if there is a value less than 50,000 other than zero, it must mean that the organization decided to submit to the IRS, because otherwise they would be listed as a zero. It is not possible to distinguish a true zero from a zero due to not meeting the threshold of 50,000 and just not submitting. See [this guide](https://github.com/jhudsl/Baltimore_nonprofits_assets/blob/8094191b88bcef6503c132c7cc73408c12ddc916/Guide_to_Using_NCCS_Data_202.pdf), page 5 in the "minimum filing threshold" section.

It therefore makes sense to remove zero values and to report this caveat that the data is incomplete because many nonprofits that had assets less than 50,000 are not included.

However for the high vs nonhigh asset we could keep these - because zero values would still be less than the threshold regardless.

Adding to this NA values can be considered less than 50000, as organizations are not required to report an amount if they have less than 50000.

# Tidying data and Exploratory Analysis

## Asset amount

First let's check how many zero values there are for asset amounts.

```{r}
#df_simplified <-sf::st_as_sf(df_simplified)
df_simplified %>% filter(F990_TOTAL_ASSETS_RECENT==0)%>% nrow()
```

Now we will check if there are `NA` values for asset amounts.

```{r, fig.height= 8}
gg_miss_var(df_simplified)
```

Yes, indeed there are...

NA and zero values likely mean the nonprofit did not need to submit to the IRS.
It is impossible to know however, if a zero is actually a true zero. NA values could mean something else. 

Thus, we will recode asset amount based on a threshold of greater than or equal to 500,000 as high asset and less than 500,000 (including zero) as not high asset.
Note we keep our NA values with this recoding.

Note: F990_TOTAL_ASSETS_RECENT was ASSET_AMT with the old files

```{r}
df_simplified<-df_simplified %>%
  #create a variable about high asset amount (threshold being $500,000)
  mutate(ASSET_High = case_when(F990_TOTAL_ASSETS_RECENT   >= 500000 ~ TRUE,
                                F990_TOTAL_ASSETS_RECENT   < 500000 ~ FALSE))
```

Here we can see the NA values:

```{r}
table(df_simplified$ASSET_High, useNA = "always")
```

Now we will replace `NA` values with `False` as well:

```{r}
 df_simplified <- df_simplified %>%  
  mutate(ASSET_High = replace_na(ASSET_High, FALSE)) #NA values will be coded as not high asset (if no cases match the other two F990_TOTAL_ASSETS_RECENT statements then code as FALSE) based on the above logic
```

Check that this worked and that there are no NA values now:

```{r}
table(df_simplified$ASSET_High, useNA = "always")
```

Now we will convert these to text as another variable and also create a log version of the asset amount to normalize it, as plots and analysis may be easier to interpret if there are many values that are high or low.

```{r}
 df_simplified<-df_simplified %>%
  mutate(ASSET_High_text = case_when(ASSET_High  == TRUE ~ "High Asset",
                                     ASSET_High  == FALSE ~ "Low Asset")) %>%
  # we will also create new log of asset amount variable
  mutate(ASSET_AMT_log = log(F990_TOTAL_ASSETS_RECENT)) # for assets of zero will be neg inf- so likely good to filter out if using this
```

## Neighborhood category

Next we will modify the data to include a variable about the percentage of African American/Black people.
```{r}
# create new Percent_AA variable by converting
# Blk_Afam (was `Normalized African American Population`) variable 
# into a percentage and rounding
#dictionary shows: Blk_AfAm = Black or African American alone population (P3)
# Population = Total population (P3) https://data.baltimorecity.gov/datasets/baltimore::neighborhood-statistical-area-nsa-boundaries/about
 df_simplified<-df_simplified %>%
  mutate(Percent_AA = 
           round(Blk_AfAm/Population*100, digits = 2))  %>%

  # create new Majority_AA variable that indicates if Percent_AA is greater than 50% or not
  mutate(Majority_AA = case_when(
    Percent_AA > 50 ~ "Yes", 
    Percent_AA <  50 ~ "No")) %>%
  # create a new variable about this in text
   mutate(Neighborhood = case_when(
    Percent_AA > 50 ~ "Majority\nBlack", 
    Percent_AA <  50 ~ "Majority\nNon-Black")) %>% 
  # make this a factor and order by level appearance in the data
  mutate(Neighborhood = as_factor(Neighborhood),
         Neighborhood = forcats::fct_inorder(Neighborhood))
```

## Quantile data
To group the data by quantiles, we first remove organizations with zero assets because we don't know if zero values are real. If assets are under 50,000, organizations can report as zero also.

Similarly, NA values could be anything between 0 and less than 50,000. Thus we aren't sure what those asset amounts are.
```{r}
 # make a new dataframe without zeros and NA asset amounts
df_simplified_no_zero<-df_simplified %>%
    drop_na(F990_TOTAL_ASSETS_RECENT) %>% #redundant but shows we are dropping NA values
    filter(F990_TOTAL_ASSETS_RECENT>0) %>% # F990_TOTAL_ASSETS_RECENT must be greater than zero
  # get quartiles
    mutate(ASSET_quartile = ntile(F990_TOTAL_ASSETS_RECENT, 4)) %>%
  # create new quartile variable that specifies quartiles by text
    mutate(ASSET_quartile_text = case_when(ASSET_quartile == 1 ~ "1st_Quartile",
                                           ASSET_quartile == 2 ~ "2nd_Quartile",
                                           ASSET_quartile == 3 ~ "3rd_Quartile",
                                           ASSET_quartile == 4 ~ "4th_Quartile"))

#Now check:
table(df_simplified_no_zero$ASSET_quartile, useNA = "always")

df_simplified_no_zero%>% group_by(ASSET_quartile_text) %>% reframe(range = range(F990_TOTAL_ASSETS_RECENT))

```


Without removal (except NAs)- since these asset amounts might influence quartiles. 
```{r}

df_simplified_no_removal<-df_simplified %>%
    drop_na(F990_TOTAL_ASSETS_RECENT) %>% #dropping NA values
  # get quartiles
    mutate(ASSET_quartile = ntile(F990_TOTAL_ASSETS_RECENT, 4)) %>%
  # create new quartile variable that specifies quartiles by text
    mutate(ASSET_quartile_text = case_when(ASSET_quartile == 1 ~ "1st_Quartile",
                                           ASSET_quartile == 2 ~ "2nd_Quartile",
                                           ASSET_quartile == 3 ~ "3rd_Quartile",
                                           ASSET_quartile == 4 ~ "4th_Quartile"))

#Now check:
table(df_simplified_no_removal$ASSET_quartile, useNA = "always")

df_simplified_no_removal %>% group_by(ASSET_quartile_text) %>% reframe(range = range(F990_TOTAL_ASSETS_RECENT))
```

Turns out this doesn't really work because the 1st and 2nd quartiles can't be distinguished as we don't know if the values of 0 are actually some number below 50,000 and both quartlies have a max of less than 50,000. So we will stick with our removal.

## National Taxonomy of Exempt Entities (NTEE) recoding

To provide more information to readers about what the nonprofits do, we will convert the National Taxonomy of Exempt Entities (NTEE) codes based on [this](https://urbaninstitute.github.io/nccs-legacy/ntee/ntee.html) and [this (see page 15)](https://www.irs.gov/pub/irs-tege/p4838.pdf).

The NTEE_IRS variable appears to be the most complete

NTEE_IRS was NTEE_CD in the older raw files

```{r}
df_simplified <-df_simplified %>%
  mutate(NTEE_text = case_when(
    str_starts(NTEE_IRS, pattern = "A")~ "Arts", # if NTEE_IRS starts with A make new variable value "Arts" etc.
    str_starts(NTEE_IRS, pattern = "B") ~ "Education",
    str_starts(NTEE_IRS, pattern = "C|D") ~ "Environment/Animals", # if NTEE_IRS value starts with C or D make new variable value "Environment/Animals"
    str_starts(NTEE_IRS, pattern = "E|F|G|H") ~ "Health",
    str_starts(NTEE_IRS, pattern = "I|J|K|L|M|N|O|P") ~ "Human Services",
    str_starts(NTEE_IRS, pattern = "Q") ~ "International Affairs",
    str_starts(NTEE_IRS, pattern = "R|S|T|U|V|W") ~ "Societal Benefit",
    str_starts(NTEE_IRS, pattern = "X") ~ "Religious",
    TRUE ~ "Other")) #everything else will be Other
```


Also for the quantile data:
```{r}
df_simplified_no_zero <-df_simplified_no_zero %>%
  mutate(NTEE_text = case_when(
    str_starts(NTEE_IRS, pattern = "A")~ "Arts", # if NTEE_IRS starts with A make new variable value "Arts" etc.
    str_starts(NTEE_IRS, pattern = "B") ~ "Education",
    str_starts(NTEE_IRS, pattern = "C|D") ~ "Environment/Animals", # if NTEE_IRS value starts with C or D make new variable value "Environment/Animals"
    str_starts(NTEE_IRS, pattern = "E|F|G|H") ~ "Health",
    str_starts(NTEE_IRS, pattern = "I|J|K|L|M|N|O|P") ~ "Human Services",
    str_starts(NTEE_IRS, pattern = "Q") ~ "International Affairs",
    str_starts(NTEE_IRS, pattern = "R|S|T|U|V|W") ~ "Societal Benefit",
    str_starts(NTEE_IRS, pattern = "X") ~ "Religous",
    TRUE~ "Other")) # everything else will be Other
```

## Save data for maps

```{r}
write_rds(df_simplified, file = "data/processed/formaps.rds")
write_rds(df_simplified_no_zero, file = "data/processed/formaps_nozero.rds")
```

# Visualizations and Analysis

## Deeper possible visualizations 

First without log normalization figure:
```{r}
df_simplified_no_zero %>% 
ggplot(aes(y = F990_TOTAL_ASSETS_RECENT, x = Percent_AA)) +
  geom_point() + geom_smooth(method = "loess")

```
We can see that some of the dat points are much higher and this makes it challenging to see the lower data values. 

Now let's look at normalized version.

Overall log Asset amount figure:
```{r}
df_simplified_no_zero %>% 
ggplot(aes(y = ASSET_AMT_log, x = Percent_AA)) +
  geom_point() + geom_smooth(method = "loess")


```



## Quartile plots


Quartiles with log asset data:
```{r}
df_simplified_no_zero %>% 
ggplot(aes(y = ASSET_AMT_log, x = Percent_AA)) +
  geom_point() + facet_wrap(~ ASSET_quartile_text, scales = "free") +geom_smooth()
```






Look at log asset data for each NTEE type- **remember the caveat that there are many organizations that are not included because of NA or zero value F990_TOTAL_ASSETS_RECENT**. However, still we can see that there is a trend towards lower amount of assets for most categories even with this limited data.

```{r}
df_simplified_no_zero %>% drop_na(NTEE_text) %>%
  ggplot(aes(y = ASSET_AMT_log, x = Neighborhood)) +
  geom_boxplot()+ geom_jitter(width = .08) + 
  facet_wrap(~ NTEE_text, scales = "free_y") + 
  geom_smooth(method = "lm", se=TRUE, aes(group=1))
```

Compare all organizations by neighborhood AA status for log asset data. *remember the caveat that there are many organizations that are not included because of NA or zero value F990_TOTAL_ASSETS_RECENT*

```{r}
df_simplified_no_zero %>% 
  ggplot(aes(y = ASSET_AMT_log, x = Neighborhood)) +
  geom_boxplot()+ geom_jitter(width = .08) + geom_smooth(method = "lm", se=TRUE, aes(group=1))
```

## Association Tests

```{r}

summary(glm(data = df_simplified_no_zero, F990_TOTAL_ASSETS_RECENT ~Percent_AA)) # for every increase in percent AA of the neighborhood there was a 266,249$ decrease in asset amount of the nonprofits in the neighborhood
# there is a less than 5% risk of concluding that an association exists between asset amount a percent AA of neighborhood when there is no actual association.


hist(df_simplified_no_zero$ASSET_AMT_log)
summary(glm(data = df_simplified_no_zero, ASSET_AMT_log~Percent_AA)) # for every increase in percent AA of the neighborhood there was a 266,249$ decrease in asset amount of the nonprofits in the neighborhood


glm(data = df_simplified_no_zero, ASSET_AMT_log ~ Percent_AA) %>% plot(which = 1:3)

#nonparametric test - because the residiuals looked skewed in the above qqplot
cor.test(df_simplified_no_zero$F990_TOTAL_ASSETS_RECENT, df_simplified_no_zero$Percent_AA, method = "spearman", exact = FALSE)

```

Look at quartiles with log asset data:
*remember the caveat that there are many organizations that are not included because of NA or zero value F990_TOTAL_ASSETS_RECENT*

```{r}
df_simplified_no_zero %>%
  ggplot(aes(y = ASSET_AMT_log, x = Neighborhood)) +
  geom_boxplot()+ geom_jitter(width = .08) + geom_smooth(method = "lm", se=TRUE, aes(group=1)) + facet_wrap(~ASSET_quartile_text, scales = "free_y")

```

First we will remove geo data to make it easier to see results:

```{r}
df_simplified_no_zero <-df_simplified_no_zero %>% st_drop_geometry()
df_simplified <-df_simplified %>% st_drop_geometry()
```


First create data to make visualization easier
*caveat for the data:  that there are many organizations that are not included because of NA or zero value F990_TOTAL_ASSETS_RECENT*

```{r}
quartile_data <-df_simplified_no_zero %>% 
  group_by(ASSET_quartile_text, Neighborhood) %>% 
  count()
quartile_data
```

Create percentage variable for each quantile
```{r}
quartile_data <- quartile_data %>%
  group_by(ASSET_quartile_text) %>% 
  mutate(Percent  = round(n/sum(n)*100)) 
quartile_data
```

Visuals...of the above data:

```{r}

quart_plot <- quartile_data %>% 
  ggplot(aes(x= ASSET_quartile_text, y = Percent,  fill = Neighborhood)) + 
    geom_col(position = position_dodge(width = .9))+
     scale_y_continuous(labels = function(x) paste0(x, "%")) +
     ylim(0,100) +
    scale_fill_grey() +
    theme_linedraw() +
    geom_text(aes(label = paste0(Percent, "%")), position = position_dodge(width = .9), vjust = -.5) 


quart_plot + labs(x = "Quartile based on nonprofit asset amount", y = "Percentage of nonprofits in the asset quartile")

```

**this does NOT include all 4,082 organizations**


## Overall Percentage Plot

First let's get a count of each - **NOTE we are keeping zero values and NA as low asset**!
The NA neighborhood means there is only one neighborhood that did not fit the categories or have information. We can drop this neighborhood.
```{r}
df_simplified %>%
  count(ASSET_High_text, Neighborhood)

df_simplified <-df_simplified %>%
  drop_na(Neighborhood)

df_simplified %>%
  count(ASSET_High_text, Neighborhood)
```


```{r}
High_asset_data <-df_simplified %>% 
  group_by(ASSET_High_text, Neighborhood) %>% 
  count() 
High_asset_data
```

Create percentage variable for each category:
```{r}
High_asset_data <- High_asset_data %>%
  group_by(Neighborhood) %>% 
  mutate(Percent_AA_cat = round(n/sum(n)*100)) 
High_asset_data
```

Visuals...of the above data:

```{r}

High_asset_data %>% 
  ggplot(aes(x= Neighborhood, y = Percent_AA_cat,  fill = ASSET_High_text)) + 
    geom_col(position = position_dodge(width = .9))+
     scale_y_continuous(labels = function(x) paste0(x, "%")) +
     ylim(0,100) +
    geom_text(aes(label = paste0(Percent_AA_cat, "%")), position = position_dodge(width = .9), vjust = -.5) +
  ylab("Percent of Neighborhood Category") +
  theme_linedraw() +
  scale_fill_grey() +
  theme(legend.title = element_blank())
```
**this includes all 4,082 organizations**

## High vs non asset by category
First create data to make visualization easier

```{r}
High_asset_data <-df_simplified %>%
  group_by(ASSET_High_text, Neighborhood, NTEE_text) %>% 
  count()
High_asset_data

#Create percentage variable for each category
High_asset_data <- High_asset_data %>%
  group_by(NTEE_text) %>% 
  mutate(Percent_ntee_cat = round(n/sum(n)*100)) 
High_asset_data


```

Visuals...of the above data:

```{r, eval = FALSE}

High_asset_data %>% 
  ggplot(aes(x= Neighborhood, y = Percent_ntee_cat,  fill = ASSET_High_text)) + 
    geom_col(position = position_dodge(width = .9))+
     scale_y_continuous(labels = function(x) paste0(x, "%")) +
    ylim(0, 100) +
    geom_text(aes(label = paste0(Percent_ntee_cat, "%")), position = position_dodge(width = .9), vjust = -.5) + facet_wrap(~NTEE_text) +
  theme_linedraw() +
  scale_fill_grey() +
  theme(legend.title = element_blank()) +
  ylab("Percentage for each category")

```

**this includes all 4,082 organizations**

## Count plots/Tables

### Different kinds of orgs

```{r}
library(forcats)
df_simplified %>% group_by(NTEE_text) %>%summarize(count = n()) %>% 
  mutate(NTEE_text = str_replace(string = NTEE_text, pattern = "NA", replacement = "Unclassified")) %>%
 mutate(Percentage = round(count/sum(count)*100, digits = 2)) %>%
  arrange(NTEE_text)

Total_NTEE <-df_simplified %>% group_by(NTEE_text) %>%summarize(total_count = n()) %>% 
  mutate(NTEE_text = str_replace(string = NTEE_text, pattern = "NA", replacement = "Unclassified")) %>%
  arrange(NTEE_text)

```


```{r}
df_simplified %>% 
  group_by(NTEE_text, Neighborhood) %>%
  summarize(count = n()) %>% 
  mutate(NTEE_text = as_factor(NTEE_text)) %>%
  ggplot(aes(x = fct_reorder(NTEE_text, count, min), y = count , fill = Neighborhood)) + 
  scale_fill_viridis_d() +
  geom_col(position =position_dodge(width = .9))  + 
  ylab ("Number of Organizations") +
  theme_linedraw() +
  theme(axis.text.x = element_text(angle = 60, vjust = .5),
        axis.title.x = element_blank()) +
  scale_fill_grey()


 
```


**This includes all 4,082 organizations** There was no removal of organizations based on asset amount, just to get a sense of what oganizations are in Baltimore.



```{r}

plot2 <- df_simplified %>% 
    mutate(NTEE_text = as_factor(NTEE_text),
         NTEE_text = forcats::fct_relevel(NTEE_text, "International Affairs", "Environment/Animals", "Arts", "Religious", "Health","Education", "Societal Benefit", "Human Services", "NA" )) %>%
  group_by(NTEE_text, Neighborhood, ASSET_High_text) %>%
  summarize(count = n()) %>% 
  ggplot(aes(x = NTEE_text, y = count , fill = Neighborhood)) + 
  geom_col(position =position_dodge(width = .9))  + 
  facet_grid(rows = vars(ASSET_High_text)) +
  ylab ("Number of Organizations") +
  theme_linedraw() +
  theme(axis.text.x = element_text(angle = 60, vjust = .5),
        axis.title.x = element_blank()) +
  scale_fill_grey()
  
plot2

```


**This includes all 4,082 organizations** There was no removal of organizations based on asset amount, just to get a sense of what oganizations are in Baltimore.


### High Asset Orgs
 
Based on Asset Amount (F990_TOTAL_ASSETS_RECENT)

```{r}
High_counts <- df_simplified %>% 
    mutate(NTEE_text = as_factor(NTEE_text),
        NTEE_text = forcats::fct_relevel(NTEE_text, "International Affairs", "Environment/Animals", "Arts", "Religious", "Health","Education", "Societal Benefit", "Human Services", "NA" )) %>%
  group_by(NTEE_text, ASSET_High_text) %>%
  summarize(count = n()) %>% filter(ASSET_High_text == "High Asset") %>%
    mutate(NTEE_text = str_replace(string = NTEE_text, pattern = "NA", replacement = "Unclassified"))

  
full_join(Total_NTEE, High_counts, join_by(NTEE_text)) %>%
   mutate("Percentage_of_each_code" = round(count/total_count *100, digits = 2)) %>%
  arrange(NTEE_text) 
```

Based on BMF_ASSET_CODE (Where 5 means >=500,000)

```{r}
High_counts <- df_simplified %>% 
    mutate(NTEE_text = as_factor(NTEE_text),
        NTEE_text = forcats::fct_relevel(NTEE_text, "International Affairs", "Environment/Animals", "Arts", "Religious", "Health","Education", "Societal Benefit", "Human Services", "NA" )) %>%
  mutate(ASSET_CD_High = case_when(BMF_ASSET_CODE >= 5 ~ "High",
                                   BMF_ASSET_CODE < 5 ~ "Low")) %>%
  group_by(NTEE_text, ASSET_CD_High) %>%
  summarize(count = n()) %>% filter(ASSET_CD_High == "High") %>%
    mutate(NTEE_text = str_replace(string = NTEE_text, pattern = "NA", replacement = "Unclassified"))

  
full_join(Total_NTEE, High_counts, join_by(NTEE_text)) %>%
   mutate("Percentage_of_each_code" = round(count/total_count *100, digits = 2)) %>%
  arrange(NTEE_text) 
```

### Counts across neighborhood type and NTEE

   BMF_ASSET_CODE was ASSET_CD in older raw files
   
   
 todo: this is misaligned... need to fix
```{r}
Count_by_neighborhood_type <- df_simplified %>% 
    mutate(NTEE_text = as_factor(NTEE_text),
        NTEE_text = forcats::fct_relevel(NTEE_text, "International Affairs", "Environment/Animals", "Arts", "Religious", "Health","Education", "Societal Benefit", "Human Services", "NA" )) %>%
  mutate(ASSET_CD_High = case_when(BMF_ASSET_CODE >= 5 ~ "High",
                                   BMF_ASSET_CODE < 5 ~ "Low")) %>%
  group_by(NTEE_text, Majority_AA) %>%
  summarize(count = n())  %>%
    mutate(NTEE_text = str_replace(string = NTEE_text, pattern = "NA", replacement = "Unclassified"))

```


```{r}

renamed_perc_data <-full_join(Total_NTEE, Count_by_neighborhood_type) %>%
   mutate("Percentage_of_each_code" = round(count/total_count *100, digits = 2)) %>%
  arrange(NTEE_text) %>%
  pivot_wider(names_from = Majority_AA, values_from = count:Percentage_of_each_code) %>% 
  dplyr::select(NTEE_text, total_count, count_Yes, Percentage_of_each_code_Yes,  count_No, Percentage_of_each_code_No) %>%
  pivot_longer(-NTEE_text) %>%
  mutate(name = case_when(
            name == "total_count" ~ "Total",
            name == "count_Yes" ~"Count_Majority_Black",
            name == "Percentage_of_each_code_Yes" ~ "Perc_Maj_Black",
            name == "count_No" ~ "Count_Non_Black",
            name == "Percentage_of_each_code_No" ~ "Perc_Non_Black"))
 
```

```{r}
  renamed_perc_data  %>%
  pivot_wider(names_from = name, values_from = value) %>%
  mutate(ratio = Count_Majority_Black/Count_Non_Black)


```

## Distribution of percent AA 

Now to take a look at if 50% African American makes sense. What do the neighborhoods look like?

Name was neighborhood name in the old data

```{r}

# get the neighborhood values if no removing rows for nonprofits with NA or zero assets
neighborhood_AAperc <- df_simplified %>% 
 distinct(Name, Percent_AA)

# get the neighborhood values after removing rows for nonprofits with NA or zero assets
neighborhood_AAperc_nozero <- df_simplified_no_zero %>% 
 distinct(Name, Percent_AA)
```


We can see that there are many neighborhoods that have a more extreme percentage.

```{r}

# get the neighborhood values if no removing rows for nonprofits with NA or zero assets

neighborhood_AAperc%>% pull(Percent_AA) %>% hist(main = "Black Percentage of Neighborhoods for each nonprofit")

# get the neighborhood values after removing rows for nonprofits with NA or zero assets
neighborhood_AAperc_nozero %>% pull(Percent_AA) %>% hist(main = "Black Percentage of Neighborhoods \n (removed neighborhoods with only zero or NA assets)")

```


